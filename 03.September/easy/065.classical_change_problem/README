https://www.reddit.com/r/dailyprogrammer/comments/v3a89/6152012_challenge_65_easy/

Write a program that given a floating point number, gives the number of American
dollar coins and bills needed to represent that number (rounded to the nearest 1/100,
i.e. the nearest penny). For instance, if the float is 12.33, the result would be
1 ten-dollar bill, 2 one-dollar bills, 1 quarter, 1 nickel and 3 pennies.

For the purposes of this problem, these are the different denominations of the
currency and their values:

Penny: 1 cent

Nickel: 5 cent

Dime: 10 cent

Quarter: 25 cent

One-dollar bill

Five-dollar bill

Ten-dollar bill

Fifty-dollar bill

Hundred-dollar bill

Sorry Thomas Jefferson, JFK and Sacagawea, but no two-dollar bills,
half-dollars or dollar coins!
